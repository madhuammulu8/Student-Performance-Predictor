# -*- coding: utf-8 -*-
"""DM_GaussianNB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14iQVjYV2Mc1qSdrnFGnXPnZ0s_X8S3_x
"""

import pandas as pd
import numpy as np
from sklearn import preprocessing
from sklearn.model_selection import train_test_split

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv("student_data.csv")

df["passed"] = df["passed"].astype('category')
# df.dtypes
df["passed"] = df["passed"].cat.codes
outcomes = df['passed']
data = df.drop('passed', axis = 1)
data = data.dropna()
data = data.apply(lambda col: pd.factorize(col, sort=True)[0])
scaler = preprocessing.MinMaxScaler()
scaler.fit(data)
scaled = scaler.transform(data)
train = pd.DataFrame(scaled, columns=data.columns)
temp_train = train
temp_outcomes = outcomes
X_train, X_test, y_train, y_test = train_test_split(train, outcomes, test_size=0.2, random_state=42)

#Gaussian Naive Bayes
import numpy as np
import pandas as pd
import scipy.stats as stats
import matplotlib.pyplot as plt
import seaborn as sns

class Naviesbayes():
  
    def fit(self, col, aim):
        che = np.zeros(256, dtype=int)
        che[aim.ravel()] = 1
        self.random  = np.nonzero(che)[0]
        self.mean(col, aim)
        self.stdev(col, aim)
        self.prior_prob(col, aim)

    def prior_prob(self, col, aim):
          self.prob = np.array(col.groupby(aim).apply(lambda x: len(x)) / col.shape[0])
          return self.prob

    def mean(self, col,aim):
        self.mean = np.array(col.groupby(aim).mean())
        return self.mean
    
    def stdev(self, col, aim):
        self.Variance = np.array(col.groupby(aim).var())        
        return self.Variance
    
    def prob_density(self, val, x):     
        p_den = (np.exp((-1/2)*np.power((x-self.mean[val]),2) / (2 * np.power(self.Variance[val],2)))) / (np.sqrt(2 * (22/7)* np.power(self.Variance[val],2)))
        return p_den
    
    def postercal(self, x):
        final_post = []
        i = 0
        while i < len(self.random):
            posterior = np.sum(np.log(self.prob[i] * self.prob_density(i, x)))
            final_post.append(posterior)
            i += 1
        return self.random[np.argmax(final_post)]
        
    def predict(self, col):
        pre = []
        for x in np.array(col):
          pre.append(self.postercal(x))
        return pre

    def accuracy(self, y_test, pred):
        accuracy = np.sum(y_test == pred) / len(y_test)
        return accuracy

from sklearn.model_selection import train_test_split
x = Naviesbayes()
X_train, X_test, y_train, y_test = train_test_split(temp_train, temp_outcomes, test_size = 0.2, random_state = 0)
x.fit(X_train, y_train)
predictions = x.predict(X_test)
print("Accuracy =",x.accuracy(y_test, predictions)*100)

import warnings
from sklearn import metrics
warnings.filterwarnings('ignore')
print("\nConfusion Matrix:")
print(metrics.confusion_matrix(y_test, predictions, labels=[1,2,3,4,5,6,7,8,9]))
print("\nClassification Report:")
print(metrics.classification_report(y_test, predictions, labels=[1,2,3,4,5,6,7,8,9]))

from sklearn.metrics import precision_score
print('Precision=',precision_score(y_test, predictions)*100)

from sklearn.metrics import f1_score
print("F1-Score", f1_score(y_test, predictions, average=None))

from sklearn.metrics import recall_score
print("Recall", recall_score(y_test, predictions, average=None))